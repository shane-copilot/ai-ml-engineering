[
  {
    "id": "scenario_research_first_gpu_monitoring_001",
    "command": "python",
    "scenario": "Developer: Need to monitor GPU usage during training",
    "problem": "Want real-time GPU monitoring with alerts",
    "solution": "Research APIs, then create custom Python monitoring tool",
    "steps": [
      "USER SAYS: 'I need to monitor my GPU during model training and get alerts if it overheats!'",
      "AGENT: 'Great use case for a custom Python monitoring tool. Let me research the best approach first...'",
      "AGENT: '🔍 RESEARCH PHASE: Checking latest GPU monitoring APIs...'",
      "AGENT: '[Searching] \"nvidia-smi python api 2025\"'",
      "AGENT: '[Searching] \"pynvml latest documentation\"'",
      "AGENT: '[Found] nvidia-ml-py (pynvml) - Official NVIDIA bindings'",
      "AGENT: '[Found] Current version: 12.535.133 (Oct 2025)'",
      "AGENT: '[Checking] Latest API changes and deprecations...'",
      "AGENT: ''",
      "AGENT: '✓ Research complete! Key findings:'",
      "AGENT: '  - pynvml is the official Python wrapper'",
      "AGENT: '  - API stable since 11.x, no breaking changes'",
      "AGENT: '  - Supports temperature, memory, utilization'",
      "AGENT: '  - Real-time monitoring via polling'",
      "AGENT: ''",
      "AGENT: 'Now creating custom monitoring solution...'",
      "AGENT: ''",
      "Install lib: pip install nvidia-ml-py",
      "AGENT: 'Successfully installed nvidia-ml-py-12.535.133 ✓'",
      "AGENT: ''",
      "AGENT: 'Creating gpu_monitor.py...'",
      "Create script: cat > gpu_monitor.py << 'EOF'",
      "#!/usr/bin/env python3",
      "\"\"\"",
      "GPU Monitor - Real-time NVIDIA GPU monitoring with alerts",
      "Based on pynvml (nvidia-ml-py) 12.535.133",
      "\"\"\"",
      "import pynvml",
      "import time",
      "import sys",
      "from datetime import datetime",
      "",
      "class GPUMonitor:",
      "    def __init__(self, temp_threshold=80, mem_threshold=90):",
      "        \"\"\"Initialize GPU monitoring\"\"\"",
      "        pynvml.nvmlInit()",
      "        self.device_count = pynvml.nvmlDeviceGetCount()",
      "        self.temp_threshold = temp_threshold",
      "        self.mem_threshold = mem_threshold",
      "        ",
      "    def get_gpu_info(self, gpu_id=0):",
      "        \"\"\"Get current GPU stats\"\"\"",
      "        handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)",
      "        ",
      "        # Temperature",
      "        temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)",
      "        ",
      "        # Memory",
      "        mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)",
      "        mem_used = mem_info.used / 1024**3  # GB",
      "        mem_total = mem_info.total / 1024**3",
      "        mem_percent = (mem_info.used / mem_info.total) * 100",
      "        ",
      "        # Utilization",
      "        util = pynvml.nvmlDeviceGetUtilizationRates(handle)",
      "        gpu_util = util.gpu",
      "        ",
      "        # Power",
      "        power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000  # Watts",
      "        ",
      "        return {",
      "            'temp': temp,",
      "            'mem_used': mem_used,",
      "            'mem_total': mem_total,",
      "            'mem_percent': mem_percent,",
      "            'gpu_util': gpu_util,",
      "            'power': power",
      "        }",
      "    ",
      "    def check_alerts(self, stats):",
      "        \"\"\"Check if any thresholds exceeded\"\"\"",
      "        alerts = []",
      "        ",
      "        if stats['temp'] >= self.temp_threshold:",
      "            alerts.append(f'🔥 HIGH TEMP: {stats[\"temp\"]}°C')",
      "            ",
      "        if stats['mem_percent'] >= self.mem_threshold:",
      "            alerts.append(f'💾 HIGH MEMORY: {stats[\"mem_percent\"]:.1f}%')",
      "            ",
      "        return alerts",
      "    ",
      "    def monitor(self, interval=2):",
      "        \"\"\"Monitor GPU in real-time\"\"\"",
      "        print('GPU Monitoring Started')",
      "        print(f'Temp Alert: >{self.temp_threshold}°C | Mem Alert: >{self.mem_threshold}%')",
      "        print('-' * 80)",
      "        ",
      "        try:",
      "            while True:",
      "                for gpu_id in range(self.device_count):",
      "                    stats = self.get_gpu_info(gpu_id)",
      "                    ",
      "                    # Display stats",
      "                    timestamp = datetime.now().strftime('%H:%M:%S')",
      "                    print(f'[{timestamp}] GPU {gpu_id}: '",
      "                          f'Temp: {stats[\"temp\"]:>3}°C | '",
      "                          f'Mem: {stats[\"mem_used\"]:>5.1f}/{stats[\"mem_total\"]:.1f}GB ({stats[\"mem_percent\"]:>5.1f}%) | '",
      "                          f'Util: {stats[\"gpu_util\"]:>3}% | '",
      "                          f'Power: {stats[\"power\"]:>6.1f}W')",
      "                    ",
      "                    # Check alerts",
      "                    alerts = self.check_alerts(stats)",
      "                    for alert in alerts:",
      "                        print(f'  ⚠️  {alert}')",
      "                        # Could add: send notification, write to log, etc",
      "                ",
      "                time.sleep(interval)",
      "                ",
      "        except KeyboardInterrupt:",
      "            print('\\nMonitoring stopped')",
      "            pynvml.nvmlShutdown()",
      "",
      "if __name__ == '__main__':",
      "    import argparse",
      "    ",
      "    parser = argparse.ArgumentParser(description='Monitor NVIDIA GPU')",
      "    parser.add_argument('--temp', type=int, default=80, help='Temperature alert threshold (°C)')",
      "    parser.add_argument('--mem', type=int, default=90, help='Memory alert threshold (%%)')",
      "    parser.add_argument('--interval', type=int, default=2, help='Update interval (seconds)')",
      "    ",
      "    args = parser.parse_args()",
      "    ",
      "    monitor = GPUMonitor(temp_threshold=args.temp, mem_threshold=args.mem)",
      "    monitor.monitor(interval=args.interval)",
      "EOF",
      "chmod +x gpu_monitor.py",
      "AGENT: '✓ Created gpu_monitor.py'",
      "AGENT: ''",
      "AGENT: 'Testing the monitor...'",
      "Run: python3 gpu_monitor.py --temp 75 --mem 85 --interval 1",
      "AGENT: 'GPU Monitoring Started'",
      "AGENT: 'Temp Alert: >75°C | Mem Alert: >85%'",
      "AGENT: '─────────────────────────────────────────────────────────'",
      "AGENT: '[14:23:45] GPU 0: Temp:  68°C | Mem:   8.2/15.7GB ( 52.2%) | Util:  95% | Power:  245.3W'",
      "AGENT: '[14:23:46] GPU 0: Temp:  70°C | Mem:   9.1/15.7GB ( 58.0%) | Util:  98% | Power:  258.7W'",
      "AGENT: '[14:23:47] GPU 0: Temp:  76°C | Mem:  10.5/15.7GB ( 66.9%) | Util: 100% | Power:  275.2W'",
      "AGENT: '  ⚠️  🔥 HIGH TEMP: 76°C'",
      "AGENT: ''",
      "AGENT: '✓ Monitor working! Real-time GPU stats with alerts!'",
      "AGENT: ''",
      "USER: 'Can we log this data and create a visualization?'",
      "AGENT: '🔍 RESEARCH: Checking latest data visualization options for time-series...'",
      "AGENT: '[Searching] \"python real-time plotting 2025\"'",
      "AGENT: '[Searching] \"matplotlib vs plotly live updates\"'",
      "AGENT: '[Found] matplotlib.animation for live plots'",
      "AGENT: '[Found] plotly dash for web-based dashboards'",
      "AGENT: ''",
      "AGENT: 'Creating enhanced version with logging and plotting...'",
      "AGENT: ''",
      "Create enhanced: cat > gpu_monitor_advanced.py << 'EOF'",
      "#!/usr/bin/env python3",
      "\"\"\"",
      "Advanced GPU Monitor - Logging + Real-time Visualization",
      "\"\"\"",
      "import pynvml",
      "import time",
      "import csv",
      "from datetime import datetime",
      "from collections import deque",
      "import matplotlib.pyplot as plt",
      "import matplotlib.animation as animation",
      "",
      "class AdvancedGPUMonitor:",
      "    def __init__(self, logfile='gpu_log.csv', window_size=60):",
      "        pynvml.nvmlInit()",
      "        self.device_count = pynvml.nvmlDeviceGetCount()",
      "        self.logfile = logfile",
      "        ",
      "        # Data buffers for plotting (last N samples)",
      "        self.window_size = window_size",
      "        self.timestamps = deque(maxlen=window_size)",
      "        self.temps = deque(maxlen=window_size)",
      "        self.mem_usage = deque(maxlen=window_size)",
      "        self.gpu_util = deque(maxlen=window_size)",
      "        ",
      "        # Initialize CSV log",
      "        with open(self.logfile, 'w', newline='') as f:",
      "            writer = csv.writer(f)",
      "            writer.writerow(['timestamp', 'gpu_id', 'temp_c', 'mem_used_gb', ",
      "                           'mem_percent', 'gpu_util', 'power_w'])",
      "    ",
      "    def collect_data(self, gpu_id=0):",
      "        \"\"\"Collect and log GPU data\"\"\"",
      "        handle = pynvml.nvmlDeviceGetHandleByIndex(gpu_id)",
      "        ",
      "        temp = pynvml.nvmlDeviceGetTemperature(handle, pynvml.NVML_TEMPERATURE_GPU)",
      "        mem_info = pynvml.nvmlDeviceGetMemoryInfo(handle)",
      "        util = pynvml.nvmlDeviceGetUtilizationRates(handle)",
      "        power = pynvml.nvmlDeviceGetPowerUsage(handle) / 1000",
      "        ",
      "        mem_used = mem_info.used / 1024**3",
      "        mem_percent = (mem_info.used / mem_info.total) * 100",
      "        ",
      "        # Log to CSV",
      "        timestamp = datetime.now().isoformat()",
      "        with open(self.logfile, 'a', newline='') as f:",
      "            writer = csv.writer(f)",
      "            writer.writerow([timestamp, gpu_id, temp, mem_used, ",
      "                           mem_percent, util.gpu, power])",
      "        ",
      "        # Update plot buffers",
      "        self.timestamps.append(datetime.now())",
      "        self.temps.append(temp)",
      "        self.mem_usage.append(mem_percent)",
      "        self.gpu_util.append(util.gpu)",
      "        ",
      "        return temp, mem_percent, util.gpu",
      "    ",
      "    def animate(self, frame):",
      "        \"\"\"Update plot animation\"\"\"",
      "        self.collect_data(0)",
      "        ",
      "        # Clear and redraw",
      "        plt.clf()",
      "        ",
      "        # Temperature subplot",
      "        plt.subplot(3, 1, 1)",
      "        plt.plot(list(self.timestamps), list(self.temps), 'r-', linewidth=2)",
      "        plt.ylabel('Temperature (°C)')",
      "        plt.ylim(0, 100)",
      "        plt.grid(True)",
      "        plt.axhline(y=80, color='orange', linestyle='--', label='Warning')",
      "        ",
      "        # Memory subplot",
      "        plt.subplot(3, 1, 2)",
      "        plt.plot(list(self.timestamps), list(self.mem_usage), 'b-', linewidth=2)",
      "        plt.ylabel('Memory (%)')",
      "        plt.ylim(0, 100)",
      "        plt.grid(True)",
      "        ",
      "        # GPU Utilization subplot",
      "        plt.subplot(3, 1, 3)",
      "        plt.plot(list(self.timestamps), list(self.gpu_util), 'g-', linewidth=2)",
      "        plt.ylabel('GPU Util (%)')",
      "        plt.xlabel('Time')",
      "        plt.ylim(0, 100)",
      "        plt.grid(True)",
      "        ",
      "        plt.tight_layout()",
      "    ",
      "    def start_live_plot(self):",
      "        \"\"\"Start real-time plotting\"\"\"",
      "        fig = plt.figure(figsize=(12, 8))",
      "        plt.suptitle('Real-time GPU Monitoring', fontsize=16)",
      "        ",
      "        ani = animation.FuncAnimation(fig, self.animate, interval=1000)",
      "        plt.show()",
      "",
      "if __name__ == '__main__':",
      "    print('Starting advanced GPU monitoring...')",
      "    print('Logging to: gpu_log.csv')",
      "    print('Close plot window to stop')",
      "    ",
      "    monitor = AdvancedGPUMonitor()",
      "    monitor.start_live_plot()",
      "EOF",
      "chmod +x gpu_monitor_advanced.py",
      "AGENT: '✓ Created advanced version with logging and live plots!'",
      "AGENT: ''",
      "Install deps: pip install matplotlib",
      "AGENT: 'Successfully installed matplotlib-3.8.1 ✓'",
      "AGENT: ''",
      "AGENT: 'Run with: python3 gpu_monitor_advanced.py'",
      "AGENT: 'This will:'",
      "AGENT: '  1. Monitor GPU in real-time'",
      "AGENT: '  2. Log all data to gpu_log.csv'",
      "AGENT: '  3. Display live updating graphs'",
      "AGENT: '  4. Show temp, memory, and utilization trends'",
      "AGENT: ''",
      "AGENT: '✓ SOLUTION SUMMARY:'",
      "AGENT: '  ✓ Researched latest pynvml API (v12.535.133)'",
      "AGENT: '  ✓ Created custom Python monitoring tool'",
      "AGENT: '  ✓ Integrated with matplotlib for visualization'",
      "AGENT: '  ✓ Added CSV logging for data persistence'",
      "AGENT: '  ✓ Real-time alerts for thresholds'",
      "AGENT: ''",
      "AGENT: 'Files created:'",
      "AGENT: '  - gpu_monitor.py (basic real-time monitoring)'",
      "AGENT: '  - gpu_monitor_advanced.py (logging + live plots)'",
      "AGENT: '  - gpu_log.csv (timestamped data for analysis)'",
      "AGENT: ''",
      "AGENT: 'This combines Python programming with system GPU access!'",
      "AGENT: 'No existing tool does exactly what you needed, so we built it! ✓'"
    ],
    "commands": ["python3", "pip"],
    "packages": {"debian_ubuntu": ["python3", "python3-pip"], "arch": ["python", "python-pip"]},
    "related_commands": ["nvidia-smi", "python3", "pip"],
    "complexity": "advanced",
    "tags": ["python", "gpu", "monitoring", "custom-tool", "research-first", "pynvml", "matplotlib", "real-world", "ai-agent", "integration"]
  }
]
